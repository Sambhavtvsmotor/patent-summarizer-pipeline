# ğŸ“„ Patent Extraction Pipeline â€” SSWA + Local BART Summarizer

## âœ… Project Overview

This pipeline processes patent data end-to-end:
1. Extracts relevant features from raw patent documents (Abstract, Claims, CPC Codes, etc.).
2. Cleans and pre-processes text with stopword removal.
3. Applies a **Semantic Similarity Weighted Algorithm (SSWA)** to rank the most relevant sentences.
4. Generates **dual input prompts** (Original Abstract + SSWA-ranked sentences).
5. Feeds the prompt to a **local BART Sequence-to-Sequence model** for fluent, abstractive summaries.
6. Saves the output in an Excel sheet for further use (e.g., building Knowledge Graphs).

---

## âœ… What We Added Today [2025-07-02]

**ğŸ¯ Key features implemented:**
- Integrated `sentence-transformers` for semantic similarity scoring.
- Built the `sswa_rank_sentences()` function using **MiniLM-L6-v2** embeddings.
- Designed a **Dual Input strategy** that combines:
  - The full **original Abstract** (for domain style & coherence).
  - The top N **key sentences** from Claims (for technical details).
- Integrated **offline local BART** (`facebook/bart-large-cnn`).
- Replaced fragile `pipeline()` usage with a robust `tokenizer` + `model.generate()` pattern.
- Solved `IndexError` issues by enforcing token truncation with `max_length=1024`.
- Final output: `output/patents_details_with_bart_summary.xlsx`  
  âœ Includes a new `SSWA BART Summary` column.

---

## âœ… ğŸ“‚ Folder Structure

Python Code/ 
â”œâ”€â”€ myenv/ 
â”œâ”€â”€ patent_documents/ 
â”œâ”€â”€ Rough/
â”œâ”€â”€ Scripts/
     	â”œâ”€â”€ script.py
		â”œâ”€â”€ built._kg.py
		â”œâ”€â”€ finetune.py
		â”œâ”€â”€ keybert.py
		â”œâ”€â”€ sswa_pipeline.py
		â”œâ”€â”€ requirements.txt
 		â”œâ”€â”€ README.md
     	â”œâ”€â”€ output/ 
				â””â”€â”€ patents_details.xlsx 
				â””â”€â”€ patents_details_with_offline_summary.xlsx


---

## âœ… ğŸ”‘ How It Works

**1ï¸âƒ£** Loads `patents_details.xlsx` with your processed patent data.

**2ï¸âƒ£** For each row:
   - Ranks Claims sentences by similarity to the Abstract.
   - Combines Abstract + top-ranked sentences into a dual-input chunk.

**3ï¸âƒ£** Uses `BartTokenizer` + `BartForConditionalGeneration` to:
   - Truncate safely to the modelâ€™s limit (1024 tokens).
   - Generate a fluent summary using beam search.

**4ï¸âƒ£** Appends the generated summary to a new column.

**5ï¸âƒ£** Saves everything to a versioned Excel file for downstream tasks.

---




## âœ… How to run

1. Activate your virtual environment:
      	.\myenv\Scripts\activate   # Windows
   	source myenv/bin/activate  # Linux/Mac

2. Install dependencies:
	pip install -r requirements.txt

3. Run:
	python script.py

4. Your final file will be at:
		Scripts/output/patents_details_with_bart_summary.xlsx

Input one or more patent/application numbers separated by commas.

âœ… Dependencies
serpapi for Google Patents search

pandas for data handling

openpyxl for Excel export

nltk or spacy for text cleaning


ğŸ“Œ Notes
Always close patents_details.xlsx before running the script.

Stop words are defined in patent_stop_words â€” update this as you refine your NLP pipeline.




# ğŸ“… DAILY PROGRESS LOG â€” [2025-07-03]

---

## âœ… Overview

**Goal:** Refine the patent processing pipeline: extraction â†’ cleaning â†’ semantic ranking â†’ summarization â†’ knowledge graph.

---

## âœ… 1ï¸âƒ£ Patent Data Pipeline

- âœ”ï¸ Extracted **Title**, **Publication/Application Number**, **Abstract**, **Claims**, **Summary**, **CPC Classifications**, **Inventors**, and **PDF link**.
- âœ”ï¸ Added **stopword removal** step for text cleaning.
- âœ”ï¸ Appended data to **Excel** (`patents_details.xlsx`) â€” does not overwrite existing data.

---

## âœ… 2ï¸âƒ£ SSWA (Semantic Similarity With Attention)

- âœ”ï¸ Used **SentenceTransformer** (`all-MiniLM-L6-v2`) to rank claim sentences against the abstract.
- âœ”ï¸ Implemented **Top-N** selection for dual-phase summarization input.

---

## âœ… 3ï¸âƒ£ BART Summarizer

- âœ”ï¸ Ran local **`facebook/bart-large-cnn`** summarizer:
  - Single input (claims only)
  - Dual input (abstract + top-ranked claims)
- âœ”ï¸ Handled truncation & input length.
- âœ”ï¸ Stored generated BART summaries back to Excel.

---

## âœ… 4ï¸âƒ£ Knowledge Graph (KG)

- âœ”ï¸ Built KG in **NetworkX**:
  - Nodes: `Patent`, `Inventor`, `CPC`, `KeyPhrase`
  - Edges: `INVENTED_BY`, `CLASSIFIED_AS`, `MENTIONS`
- âœ”ï¸ Saved:
  - `patent_kg.graphml` for **Neo4j** or **Gephi**.
  - `patent_kg_snapshot.png` with clear node colors and labels.

---

## âœ… 5ï¸âƒ£ Keyphrase Extraction

- âœ”ï¸ Tried **KeyBERT + KeyphraseVectorizers**
- âš ï¸ Hit `blis` build error due to missing C++ build tools.
- âœ”ï¸ Verified **KeyBERT** works standalone with `SentenceTransformer`.

---

## âœ… 6ï¸âƒ£ BART Fine-Tuning Attempt

- âœ”ï¸ Set up domain fine-tuning script.
- âš ï¸ Encountered `TrainingArguments` version mismatch.
- Currently Working on this, trying to understand the issue

---

## ğŸŸ¢ Whatâ€™s Working Now

| Step | Status |
|------|--------|
| SerpAPI extraction | âœ… |
| Excel append | âœ… |
| Text cleaning | âœ… |
| SSWA sentence ranking | âœ… |
| Local BART summarization | âœ… |
| KG build & export | âœ… |
| KeyBERT (default embedder) | âœ… |

---

## ğŸ”§ Next Steps

- Fix local build for `KeyphraseVectorizers` (install MSVC or test on Colab)
- Fine-tune **BART** on cleaned domain data (Colab recommended)
- Expand KG: load into **Neo4j** and test graph queries
- Try chunked input for longer abstracts/claims with BART
- Prepare final README updates for project push to GitHub

---

## ğŸ—‚ï¸ Files Updated Today

- `Scripts/script.py`
- `Scripts/sswa_pipeline.py`
- `Scripts/build_kg.py`
- `output/patents_details.xlsx`
- `output/patent_kg.graphml`
- `output/patent_kg_snapshot.png`

---

## âš¡ Keep It Rolling!

> ğŸš€ We have a fully functional pipeline â€” only advanced NLP vectorizer and fine-tuning steps need environment tuning.  
> All base steps work end-to-end!

---

_âœï¸ Prepared by: [Team TIP] â€” [2025-07-03]_
