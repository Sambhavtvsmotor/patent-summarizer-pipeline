# ğŸ“„ Patent Extraction Pipeline â€” SSWA + Local BART Summarizer

## âœ… Project Overview

This pipeline processes patent data end-to-end:
1. Extracts relevant features from raw patent documents (Abstract, Claims, CPC Codes, etc.).
2. Cleans and pre-processes text with stopword removal.
3. Applies a **Semantic Similarity Weighted Algorithm (SSWA)** to rank the most relevant sentences.
4. Generates **dual input prompts** (Original Abstract + SSWA-ranked sentences).
5. Feeds the prompt to a **local BART Sequence-to-Sequence model** for fluent, abstractive summaries.
6. Saves the output in an Excel sheet for further use (e.g., building Knowledge Graphs).

---

## âœ… What We Added Today

**ğŸ¯ Key features implemented:**
- Integrated `sentence-transformers` for semantic similarity scoring.
- Built the `sswa_rank_sentences()` function using **MiniLM-L6-v2** embeddings.
- Designed a **Dual Input strategy** that combines:
  - The full **original Abstract** (for domain style & coherence).
  - The top N **key sentences** from Claims (for technical details).
- Integrated **offline local BART** (`facebook/bart-large-cnn`).
- Replaced fragile `pipeline()` usage with a robust `tokenizer` + `model.generate()` pattern.
- Solved `IndexError` issues by enforcing token truncation with `max_length=1024`.
- Final output: `output/patents_details_with_bart_summary.xlsx`  
  âœ Includes a new `SSWA BART Summary` column.

---

## âœ… ğŸ“‚ Folder Structure

Python Code/ 
â”œâ”€â”€ myenv/ 
â”œâ”€â”€ patent_documents/ 
â”œâ”€â”€ Rough/
â”œâ”€â”€ Scripts/
     	â”œâ”€â”€ script.py
		â”œâ”€â”€ sswa_pipeline.py
		â”œâ”€â”€ requirements.txt
 		â”œâ”€â”€ README.md
     	â”œâ”€â”€ output/ 
				â””â”€â”€ patents_details.xlsx 
				â””â”€â”€ patents_details_with_offline_summary.xlsx


---

## âœ… ğŸ”‘ How It Works

**1ï¸âƒ£** Loads `patents_details.xlsx` with your processed patent data.

**2ï¸âƒ£** For each row:
   - Ranks Claims sentences by similarity to the Abstract.
   - Combines Abstract + top-ranked sentences into a dual-input chunk.

**3ï¸âƒ£** Uses `BartTokenizer` + `BartForConditionalGeneration` to:
   - Truncate safely to the modelâ€™s limit (1024 tokens).
   - Generate a fluent summary using beam search.

**4ï¸âƒ£** Appends the generated summary to a new column.

**5ï¸âƒ£** Saves everything to a versioned Excel file for downstream tasks.

---




## âœ… How to run

1. Activate your virtual environment:
      	.\myenv\Scripts\activate   # Windows
   	source myenv/bin/activate  # Linux/Mac

2. Install dependencies:
	pip install -r requirements.txt

3. Run:
	python script.py

4. Your final file will be at:
		Scripts/output/patents_details_with_bart_summary.xlsx

Input one or more patent/application numbers separated by commas.

âœ… Dependencies
serpapi for Google Patents search

pandas for data handling

openpyxl for Excel export

nltk or spacy for text cleaning


ğŸ“Œ Notes
Always close patents_details.xlsx before running the script.

Stop words are defined in patent_stop_words â€” update this as you refine your NLP pipeline.

Backups are saved in output/ with timestamps.